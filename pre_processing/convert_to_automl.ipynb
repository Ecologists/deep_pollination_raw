{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Ecologists\n",
    "### AutoML Data Converter\n",
    "This notebook converts cvs data to AutoML Format for Codalab challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqlVY973te17"
   },
   "source": [
    "\n",
    "The input csv file should have the following structure:\n",
    "<ul>\n",
    "  <li> n+1 columns where n are the features of the dataset\n",
    "  <li> the last column should the label/class of the example\n",
    "  <li> name of the last column should be <b>label</b>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "\n",
    "There are some variables which have to be initialized with required value to be used in the conversion\n",
    "<ul>\n",
    "<li> <b>pathRes</b> .........: path of the directory where the csv file is located\n",
    "<li> <b>fileName</b> ........: csv filename including the extention .csv ___ Example: data.csv\n",
    "<li> <b>path</b> ................: [Do not change] complete path of the csv file\n",
    "<li> <b>pathAuto</b> ........: [Do not change] path of directory where the converted AutoML files will be saved. [Default: same path as of the csv file]\n",
    "<li> <b>pathAuto</b> ........: path of directory where the converted AutoML files will be saved. [Default: same path as of the csv file]\n",
    "<li> <b>pathPublic</b> ......: [Do not change] path of public_data \n",
    "<li> <b>pathSample</b> ....: [Do not change] path of sample_date\n",
    "<li> <b>dataName</b> .......: name of the dataset to be created\n",
    "<li> <b>ChalName</b> .......: name of the challenge for which the data is being converted\n",
    "<li> <b>taskName</b> ........: name of the task of the challenge ___ Example: Regression\n",
    "<li> <b>targetType</b> .......: type of the label ___ Example: Numerical\n",
    "<li> <b>featType</b> ...........: type of the features ___ Example: Numerical\n",
    "<li> <b>metric</b> ...............: name of the performance metric ___ Example: accuracy\n",
    "<li> <b>percTest</b> ...........: percentage of the test set\n",
    "<li> <b>percValid</b> ..........: percentage of the validation set\n",
    "<li> <b>sampleSize</b> .......: number of examples in sample_data\n",
    "<li> <b>hasMissing</b> ........: dataset has missing values\n",
    "<li> <b>hasCategorical</b> .: dataset has categorical data\n",
    "<li> <b>isSparse</b> ............: dataset has alot of zeros\n",
    "\n",
    "</ul>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTXOHiPK3f8V"
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aaFypmzntdap"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqnJte8M3sO9"
   },
   "source": [
    "**Initialization of variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LSt87aKLtdau"
   },
   "outputs": [],
   "source": [
    "pathRes = 'Data/'\n",
    "fileName = 'bees.csv'\n",
    "\n",
    "path = pathRes + fileName\n",
    "pathAuto = pathRes+'AutoML/'\n",
    "pathPublic = pathAuto+'public_data/'\n",
    "pathSample = pathAuto+'sample_data/'\n",
    "dataName = 'bee'\n",
    "chalName = 'beeVSwasp'\n",
    "taskName = 'multiclass.classification'\n",
    "targetType = 'Numerical'\n",
    "featType = 'Numerical'\n",
    "metric = 'balanced_accuracy_score'\n",
    "percTest = 0.1\n",
    "percValid = 0.1\n",
    "sampleSize = 100\n",
    "hasMissing = '0' # 0 if false, 1 if true\n",
    "hasCategorical = '0' # 0 if false, 1 if true\n",
    "isSparse = '0' # 0 if false, 1 if true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb0vvA2S3xKA"
   },
   "source": [
    "**Read CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9CibowpRtdau",
    "outputId": "9e55fbe7-1012-44fb-aa10-9e3a02562169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--/!\\-- Reading the CSV file --/!\\--\n"
     ]
    }
   ],
   "source": [
    "print('--/!\\-- Reading the CSV file --/!\\--')\n",
    "data = pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBuhb2f730sB"
   },
   "source": [
    "**Separate features and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PxDQKDDMtdav"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--/!\\-- Separating features and labels --/!\\--\n"
     ]
    }
   ],
   "source": [
    "print('--/!\\-- Separating features and labels --/!\\--')\n",
    "X = data.loc[:, data.columns != 'label']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLiODVqb37C9"
   },
   "source": [
    "**Creating Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rerJE4BVtdaw",
    "outputId": "db65ea0a-479f-4617-e19b-1383b756293d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deletion of the directory Data/AutoML/public_data/ failed\n",
      "Successfully created the directory Data/AutoML/\n",
      "Successfully created the directory Data/AutoML/public_data/\n",
      "Successfully created the directory Data/AutoML/sample_data/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(pathAuto)\n",
    "except OSError:\n",
    "    print (\"Deletion of the directory %s failed\" % pathPublic)\n",
    "else:\n",
    "    print (\"Successfully deleted the directory %s\" % pathPublic)\n",
    "\n",
    "try:\n",
    "    os.mkdir(pathAuto)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % pathAuto)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % pathAuto)\n",
    "    \n",
    "try:\n",
    "    os.mkdir(pathPublic)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % pathPublic)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % pathPublic)\n",
    "    \n",
    "try:\n",
    "    os.mkdir(pathSample)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % pathSample)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % pathSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paAgFoFY4DKk"
   },
   "source": [
    "**Saving Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_urkY3jXtdaw",
    "outputId": "7e644038-eb68-40b4-9b96-d4d3ed94d615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_feat.name is created\n"
     ]
    }
   ],
   "source": [
    "features = X.columns # Save all features of the dataset (-1 is to don't keep the labels)\n",
    "f = open(pathPublic+dataName+\"_feat.name\", \"w\") # Create the file which contains feature names\n",
    "for i in range(0,len(features)):\n",
    "    if(i!=len(features)-1):\n",
    "        f.write(features[i]+'\\n') # Normal case\n",
    "    else:\n",
    "        f.write(features[i]) # Last line\n",
    "f.close() # Close the file\n",
    "print(dataName+\"_feat.name is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RjHjOLh4NIP"
   },
   "source": [
    "**Encoding label values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5FheX-bwtdax",
    "outputId": "01535dea-0e8a-4945-f366-969933b0b710"
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y.unique())\n",
    "enc_y = le.transform(y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cr_5VQIa4Xpi"
   },
   "source": [
    "**Saving Label Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o9_ypn8ntdaz",
    "outputId": "ef3e43bd-ce8e-4830-fbd5-6f4716c79517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_label.name is created\n"
     ]
    }
   ],
   "source": [
    "labels = le.classes_\n",
    "f = open(pathPublic+dataName+\"_label.name\", \"w\") # Create the file which contains label names\n",
    "for i in range(0,len(labels)):\n",
    "    if(i!=len(labels)-1):\n",
    "        f.write(labels[i]+'\\n') # Normal case\n",
    "    else:\n",
    "        f.write(labels[i]) # Last line\n",
    "f.close()\n",
    "print(dataName+\"_label.name is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCmtAvZ34esg"
   },
   "source": [
    "**Creating Training, Validation and Test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZBtJ6DxKtdaz"
   },
   "outputs": [],
   "source": [
    "x_temp, x_test, y_temp, y_test = train_test_split(\n",
    "    X, enc_y, test_size=percTest)\n",
    "\n",
    "\n",
    "testSize = int(percTest*X.shape[0])/x_temp.shape[0] \n",
    "\n",
    "if(testSize == 0):\n",
    "    testSize = 1\n",
    "    \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_temp, y_temp, test_size= testSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P80YVCPT4yRF"
   },
   "source": [
    "**Saving train, valid and test data and solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "np0vn-w4tdaz",
    "outputId": "faba4c96-eeef-41dd-89b2-2ac25fd702a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_train.data and bee_train.solution are created\n",
      "bee_valid.data and bee_valid.solution are created\n",
      "bee_test.data and bee_test.solution are created\n"
     ]
    }
   ],
   "source": [
    "x_train.to_csv(pathPublic+dataName+\"_train.data\", header=None, index=None, sep=' ', mode='a')\n",
    "np.savetxt(pathPublic+dataName+\"_train.solution\", y_train, fmt='%d')\n",
    "print(dataName+\"_train.data and \"+dataName+\"_train.solution are created\")\n",
    "\n",
    "x_valid.to_csv(pathPublic+dataName+\"_valid.data\", header=None, index=None, sep=' ', mode='a')\n",
    "np.savetxt(pathPublic+dataName+\"_valid.solution\", y_valid, fmt='%d')\n",
    "print(dataName+\"_valid.data and \"+dataName+\"_valid.solution are created\")\n",
    "\n",
    "x_test.to_csv(pathPublic+dataName+\"_test.data\", header=None, index=None, sep=' ', mode='a')\n",
    "np.savetxt(pathPublic+dataName+\"_test.solution\", y_test, fmt='%d')\n",
    "print(dataName+\"_test.data and \"+dataName+\"_test.solution are created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-K7-0HHX45_d"
   },
   "source": [
    "**Saving Feature types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QQ1iT0sJtda0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_feat.type is created\n"
     ]
    }
   ],
   "source": [
    "typee = x_train.dtypes\n",
    "typee.to_csv(pathPublic+dataName+\"_feat.type\", header=None, index=None, sep=' ', mode='a')\n",
    "print(dataName+\"_feat.type is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbDCPsrN5ylc"
   },
   "source": [
    "**Saving Public Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ACc2ucGYtda0",
    "outputId": "c6b7f922-0432-4361-c6ef-af7390762904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_public.info is created\n"
     ]
    }
   ],
   "source": [
    "f = open(pathPublic+dataName+\"_public.info\", \"w\")\n",
    "f.write('usage = '+chalName+'\\n')\n",
    "f.write('name = '+dataName+'\\n')\n",
    "f.write('task = '+taskName+'\\n')\n",
    "f.write('target_type = '+targetType+'\\n')\n",
    "f.write('feat_type = '+featType+'\\n')\n",
    "f.write('metric = '+metric+'\\n')\n",
    "f.write('feat_num = '+str(len(features))+'\\n')\n",
    "f.write('target_num = '+str(len(labels))+'\\n')\n",
    "f.write('label_num = '+str(len(labels))+'\\n')\n",
    "f.write('train_num = '+str(len(x_train))+'\\n')\n",
    "f.write('valid_num = '+str(len(x_valid))+'\\n')\n",
    "f.write('test_num = '+str(len(x_test))+'\\n')\n",
    "f.write('has_categorical = '+hasCategorical+'\\n')\n",
    "f.write('has_missing = '+hasMissing+'\\n')\n",
    "f.write('is_sparse = '+isSparse+'\\n')\n",
    "f.write('time_budget = 500')\n",
    "f.close()\n",
    "print(dataName+\"_public.info is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGKkQU4x53-4"
   },
   "source": [
    "**Saving Private Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_ANk9f4_tda0",
    "outputId": "ecb87fec-41b4-4487-f662-8e037ae25815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_private.info is created\n"
     ]
    }
   ],
   "source": [
    "f = open(pathPublic+dataName+\"_private.info\", \"w\")\n",
    "f.write('title = '+dataName+'\\n')\n",
    "f.write('keywords = image.classification\\n')\n",
    "f.write('authors = Grégoire Loïs, Colin FONTAINE, Jean-Francois Julien\\n')\n",
    "f.write('resource_url = https://www.mnhn.fr/fr\\n')\n",
    "f.write('contact_name = Grégoire Loïs, Colin FONTAINE, Jean-Francois Julien\\n')\n",
    "f.write('contact_url = gregoire.lois@mnhn.fr\\n')\n",
    "f.write('license = \\n')\n",
    "f.write('date_created = 30 Dec 2020\\n')\n",
    "f.write('past_usage = \\n')\n",
    "f.write('description = The data is property of MUSÉUM NATIONAL D’HISTOIRE NATURELLE. The data consists of 290,000 images including images of bees, wasps, butterflies and other insects.\\n')\n",
    "f.write('preparation = The data was processed to get uniform images of resolution 128x128. After preprocessing the data was divided into Train, Validation and Test sets. \\n')\n",
    "f.write('representation = OpenCv features extracted by the opencv algorithm from the image which represents different image properties\\n')\n",
    "f.write('real_feat_num = 2048\\n')\n",
    "f.write('probe_num = 0\\n')\n",
    "f.write('frac_probes = 0\\n')\n",
    "f.write(\"feat_type = { 'Numerical' 'Categorical' 'Binary' }\\n\")\n",
    "f.write('feat_type_freq = [1 0 0]\\n')\n",
    "f.write(\"label_names = { 'bee' 'butterfly' 'insect' 'other' 'wasp' } \\n\")\n",
    "f.write('train_label_freq = [0.30540744175263707 0.10869115236218517 0.3951133484575005 0.1501349583533425 0.04065309907433473 ]\\n')\n",
    "f.write('train_label_entropy = 1.3852419181750144\\n')\n",
    "f.write('train_sparsity = \\n')\n",
    "f.write('train_frac_missing = 0\\n')\n",
    "f.write('valid_label_freq = [0.2, 0.2, 0.2, 0.2, 0.2]\\n')\n",
    "f.write('valid_label_entropy = 1.6094379124341005\\n')\n",
    "f.write('valid_sparsity = \\n')\n",
    "f.write('valid_frac_missing = 0\\n')\n",
    "f.write('test_label_freq = [0.2, 0.2, 0.2, 0.2, 0.2]\\n')\n",
    "f.write('test_label_entropy = 1.6094379124341005\\n')\n",
    "f.write('test_sparsity = \\n')\n",
    "f.write('test_frac_missing = 0\\n')\n",
    "f.write('train_data_aspect_ratio = 0.008478365265197305')\n",
    "f.close()\n",
    "print(dataName+\"_private.info is created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSfrccgZ6AMv"
   },
   "source": [
    "**Creating Sample Data from Training set of public data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WtAYfqHBtda0"
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:sampleSize]\n",
    "y_train = y_train[:sampleSize]\n",
    "\n",
    "x_temp, x_test, y_temp, y_test = train_test_split(\n",
    "    x_train, y_train, test_size=percTest)\n",
    "\n",
    "\n",
    "testSize = int(percTest*x_train.shape[0])/x_temp.shape[0] \n",
    "if(testSize == 0):\n",
    "    testSize = 1\n",
    "    \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_temp, y_temp, test_size= testSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzYF9V-a6GrP"
   },
   "source": [
    "**Saving Sample Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NzSLD_z0tda1",
    "outputId": "5259ecb1-abb1-4e1b-80cb-d7781c011249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_train.data and bee_train.solution are created\n",
      "bee_valid.data and bee_valid.solution are created\n",
      "bee_test.data and bee_test.solution are created\n"
     ]
    }
   ],
   "source": [
    "x_train.to_csv(pathSample+dataName+\"_train.data\", header=None, index=None, sep=' ', mode='a')\n",
    "np.savetxt(pathSample+dataName+\"_train.solution\", y_train, fmt='%d')\n",
    "print(dataName+\"_train.data and \"+dataName+\"_train.solution are created\")\n",
    "\n",
    "x_valid.to_csv(pathSample+dataName+\"_valid.data\", header=None, index=None, sep=' ', mode='a')\n",
    "np.savetxt(pathSample+dataName+\"_valid.solution\", y_valid, fmt='%d')\n",
    "print(dataName+\"_valid.data and \"+dataName+\"_valid.solution are created\")\n",
    "\n",
    "x_test.to_csv(pathSample+dataName+\"_test.data\", header=None, index=None, sep=' ', mode='a')\n",
    "np.savetxt(pathSample+dataName+\"_test.solution\", y_test, fmt='%d')\n",
    "print(dataName+\"_test.data and \"+dataName+\"_test.solution are created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Kme-DvZVtda1",
    "outputId": "e6411b1d-c425-478e-c672-05f52ef9f129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_public.info is created\n"
     ]
    }
   ],
   "source": [
    "f = open(pathSample+dataName+\"_public.info\", \"w\")\n",
    "f.write('usage = '+chalName+'\\n')\n",
    "f.write('name = '+dataName+'\\n')\n",
    "f.write('task = '+taskName+'\\n')\n",
    "f.write('target_type = '+targetType+'\\n')\n",
    "f.write('feat_type = '+featType+'\\n')\n",
    "f.write('metric = '+metric+'\\n')\n",
    "f.write('feat_num = '+str(len(features))+'\\n')\n",
    "f.write('target_num = '+str(len(labels))+'\\n')\n",
    "f.write('label_num = '+str(len(labels))+'\\n')\n",
    "f.write('train_num = '+str(len(x_train))+'\\n')\n",
    "f.write('valid_num = '+str(len(x_valid))+'\\n')\n",
    "f.write('test_num = '+str(len(x_test))+'\\n')\n",
    "f.write('has_categorical = '+hasCategorical+'\\n')\n",
    "f.write('has_missing = '+hasMissing+'\\n')\n",
    "f.write('is_sparse = '+isSparse+'\\n')\n",
    "f.write('time_budget = 500')\n",
    "f.close()\n",
    "print(dataName+\"_public.info is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "z_GUoNCctda2",
    "outputId": "bd798a43-1475-43be-fdeb-7842471736ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/AutoML/sample_data/bee_feat.type'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile(pathPublic+dataName+\"_private.info\", pathSample+dataName+\"_private.info\")\n",
    "shutil.copyfile(pathPublic+dataName+\"_label.name\", pathSample+dataName+\"_label.name\")\n",
    "shutil.copyfile(pathPublic+dataName+\"_feat.name\", pathSample+dataName+\"_feat.name\")\n",
    "shutil.copyfile(pathPublic+dataName+\"_feat.type\", pathSample+dataName+\"_feat.type\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convert_to_automl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
