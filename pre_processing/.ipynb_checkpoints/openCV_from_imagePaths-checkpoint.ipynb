{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEAM ECOLOGISTS\n",
    "## Open CV features extraction from image files(image paths) and image pixels csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "#from scipy.misc import imread\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractor Class\n",
    "<div style='background-color:#FD7575; padding:3px;'>\n",
    "    <h3>Don't change</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor\n",
    "def extract_features(image_path, is_path=True, vector_size=32):\n",
    "    \n",
    "    #image = imread(image_path, mode=\"RGB\")\n",
    "    \n",
    "    if not is_path:\n",
    "        print(\"Reading image from pixel\")\n",
    "        \n",
    "        #image_path is a row of DataFrame here\n",
    "        #change the image pixels below if these are change in the csv\n",
    "        img = image_path.values[:-1].reshape(64,64,3)\n",
    "        #Mohammed the following line will store image in image variable\n",
    "        image = (img.astype(float) / 255)\n",
    "        \n",
    "    else:\n",
    "#         print(\"Reading image from path\")\n",
    "        #in MAC OS uncomment the next line\n",
    "        #image_path = image_path.replace(\"\\\\\", \"/\")\n",
    "        image = mpimg.imread(image_path)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Using KAZE, cause SIFT, ORB and other was moved to additional module\n",
    "        # which is adding addtional pain during install\n",
    "        alg = cv2.KAZE_create(threshold=0.0001)\n",
    "        # Dinding image keypoints\n",
    "        kps = alg.detect(image)\n",
    "        # Getting first 32 of them. \n",
    "        # Number of keypoints is varies depend on image size and color pallet\n",
    "        # Sorting them based on keypoint response value(bigger is better)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        # computing descriptors vector\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        # Flatten all of them in one big vector - our feature vector\n",
    "        if dsc is None:\n",
    "            print(dsc)\n",
    "            print(image_path)\n",
    "        dsc = dsc.flatten()\n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less the 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    except cv2.error as e:\n",
    "        print ('Error: ', e)\n",
    "        return None\n",
    "\n",
    "    return dsc\n",
    "\n",
    "\n",
    "#EXTRACTOR FROM PATHS FROM CSV\n",
    "def feature_extractor_from_path_in_csv(dataframe, directory_path, path_string_name, label_string_name, pickled_db_path=\"features_from_imagepaths_csv.pck\"):\n",
    "    paths = dataframe[path_string_name].tolist()\n",
    "    labels = dataframe[label_string_name].tolist()\n",
    "    \n",
    "    \n",
    "    result = {}\n",
    "    for index, f in enumerate(paths):\n",
    "        \n",
    "        f = os.path.join(directory_path, labels[index]+'_128/'+f)\n",
    "        if index%1000 == 0:  \n",
    "            print(index)\n",
    "            print ('Extracting features from image: %s label: %s' %(f,labels[index]) )\n",
    "        name = labels[index]+'_'+str(index)\n",
    "        result[name] = extract_features(f)\n",
    "        \n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open(pickled_db_path, 'wb') as fp:\n",
    "        pickle.dump(result, fp)\n",
    "        print(\"<------ Conversion completed ------>\\n <------ File saved as features_from_imagepaths_csv.pcknow ------> \\n Now convert it into .csv\")\n",
    "\n",
    "def feature_extractor_pixels_in_csv(dataframe, pickled_db_path=\"features_from_imagepixels_csv.pck\"):\n",
    "    labels = dataframe['label'].tolist()\n",
    "    \n",
    "    result = {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        print ('Extracting features from image: %s label: %s' %(index,labels[index]) )\n",
    "        name = labels[index]+'_'+str(index)\n",
    "        result[name] = extract_features(row, is_path=False)\n",
    "        \n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open(pickled_db_path, 'wb') as fp:\n",
    "        pickle.dump(result, fp)\n",
    "        print(\"<------ Conversion completed ------>\\n <------ File saved as features_from_imagepixels_csv.pcknow ------> \\n Now convert it into .csv\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#BATCH EXTACTOR FROM DIRECTORY        \n",
    "def batch_extractor(images_path, pickled_db_path=\"features.pck\"):\n",
    "    files = [os.path.join(images_path, p) for p in sorted(os.listdir(images_path))]\n",
    "\n",
    "    result = {}\n",
    "    for f in files:\n",
    "        print ('Extracting features from image %s' % f)\n",
    "        name = f.split('/')[-1].lower()\n",
    "        result[name] = extract_features(f)\n",
    "        \n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open(pickled_db_path, 'wb') as fp:\n",
    "        pickle.dump(result, fp)\n",
    "        print(\"Conversion completed - now convert in .csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matcher Class\n",
    "\n",
    "<div style='background-color:#FD7575; padding:3px;'>\n",
    "    <h3>Don't change</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher(object):\n",
    "\n",
    "    def __init__(self, pickled_db_path=\"features.pck\"):\n",
    "        with open(pickled_db_path, 'rb') as fp:\n",
    "            self.data = pickle.load(fp)\n",
    "        \n",
    "        self.names = []\n",
    "        self.matrix = []\n",
    "        for k, v in self.data.items():\n",
    "            self.names.append(k)\n",
    "            self.matrix.append(v)\n",
    "        self.matrix = np.array(self.matrix)\n",
    "        self.names = np.array(self.names)\n",
    "\n",
    "    def cos_cdist(self, vector):\n",
    "        # getting cosine distance between search image and images database\n",
    "        v = vector.reshape(1, -1)\n",
    "        return scipy.spatial.distance.cdist(self.matrix, v, 'cosine').reshape(-1)\n",
    "\n",
    "    def match(self, image_path, topn=5):\n",
    "        features = extract_features(image_path)\n",
    "        img_distances = self.cos_cdist(features)\n",
    "        # getting top 5 records\n",
    "        nearest_ids = np.argsort(img_distances)[:topn].tolist()\n",
    "        nearest_img_paths = self.names[nearest_ids].tolist()\n",
    "\n",
    "        return nearest_img_paths, img_distances[nearest_ids].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show and Run Functions\n",
    "\n",
    "<div style='background-color:#FD7575; padding:3px;'>\n",
    "    <h3>Don't change</h3>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style='background-color:#ffe342; padding:3px;'>\n",
    "    <h5>Use <code>run_batchFeatureExtractor</code> for a whole directory. You have to provide a directory path and all features will be extracted from all files in that directory</h5>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style='background-color:#ffe342; padding:3px;'>\n",
    "    <h5>Use <code>run_featureExtractor_from_paths_in_csv</code> for a csv file with image paths as a column. Don't forget to modify the name of the column in csv which contains path and the column name which contains label. And the directory path as a string where the images are stored.</h5>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style='background-color:#ffe342; padding:3px;'>\n",
    "    <h5>Use <code>run_featureExtractor_from_csv_with_images_pixels_as_features</code> for a csv file with image pixels in columns and the last column represents the label of the example with the name 'label'</h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batchFeatureExtractor():\n",
    "    ### HERE WE HAVE TO INPUT PATH OF IMAGES\n",
    "    images_path = 'Data/bee1/'\n",
    "    batch_extractor(images_path)\n",
    "    \n",
    "def run_featureExtractor_from_paths_in_csv():\n",
    "    df = pd.read_csv('../DATA/TEST/test_labels.csv')\n",
    "    path_column_name = 'image_name'\n",
    "    label_column_name = 'label'\n",
    "    directory_path = '../DATA/TEST/'\n",
    "    feature_extractor_from_path_in_csv(df, directory_path, path_column_name, label_column_name)\n",
    "    \n",
    "def run_featureExtractor_from_csv_with_images_pixels_as_features():\n",
    "    df = pd.read_csv('bee_wasps_museum.csv',  nrows=2)\n",
    "    feature_extractor_pixels_in_csv(df)\n",
    "\n",
    "    \n",
    "    \n",
    "#IGNORE FOR NOW\n",
    "def show_img(path):\n",
    "    #img = imread(path, mode=\"RGB\")\n",
    "    img = mpimg.imread(path)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "def run_matcher():\n",
    "    \n",
    "    ### HERE WE HAVE TO INPUT PATH OF IMAGES\n",
    "    images_path = 'Data/bee1/'\n",
    "    files = [os.path.join(images_path, p) for p in sorted(os.listdir(images_path))]\n",
    "    # getting 3 random images \n",
    "    sample = random.sample(files, 3)\n",
    "    \n",
    "    ma = Matcher('features.pck')\n",
    "    \n",
    "    for s in sample:\n",
    "        print('Query image ==========================================')\n",
    "        show_img(s)\n",
    "        names, match = ma.match(s, topn=3)\n",
    "        print('Result images ========================================')\n",
    "        for i in range(3):\n",
    "            # we got cosine distance, less cosine distance between vectors\n",
    "            # more they similar, thus we subtruct it from 1 to get match value\n",
    "            print('Match %s' % (1-match[i]))\n",
    "            show_img(os.path.join(images_path, names[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting from CSV with paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Extracting features from image: ../DATA/TEST/insect_128/1447696357891.jpg label: insect\n",
      "1000\n",
      "Extracting features from image: ../DATA/TEST/bee_128/240165415_d95cc9da5d_n.jpg label: bee\n",
      "2000\n",
      "Extracting features from image: ../DATA/TEST/bee_128/31154610876_bfa82d6968_n.jpg label: bee\n",
      "3000\n",
      "Extracting features from image: ../DATA/TEST/other_128/072_0007.jpg label: other\n",
      "4000\n",
      "Extracting features from image: ../DATA/TEST/insect_128/42820715035_62106ab5ee_n.jpg label: insect\n",
      "5000\n",
      "Extracting features from image: ../DATA/TEST/wasp_128/6545894085_3ba2c05f13_n.jpg label: wasp\n",
      "6000\n",
      "Extracting features from image: ../DATA/TEST/other_128/087_0007.jpg label: other\n",
      "7000\n",
      "Extracting features from image: ../DATA/TEST/butterfly_128/c2c11410-43e9-47b9-b908-ba2c681fb867.jpg label: butterfly\n",
      "8000\n",
      "Extracting features from image: ../DATA/TEST/insect_128/39494538771_8a7f707fda_n.jpg label: insect\n",
      "9000\n",
      "Extracting features from image: ../DATA/TEST/insect_128/41715571700_1a9f4d13da_n.jpg label: insect\n",
      "10000\n",
      "Extracting features from image: ../DATA/TEST/wasp_128/9270516644_d7f71b8c1b_m.jpg label: wasp\n",
      "11000\n",
      "Extracting features from image: ../DATA/TEST/wasp_128/49789124062_0cfa1c8b61_n.jpg label: wasp\n",
      "12000\n",
      "Extracting features from image: ../DATA/TEST/wasp_128/2815018549_41475bde8b_m.jpg label: wasp\n",
      "<------ Conversion completed ------>\n",
      " <------ File saved as features_from_imagepaths_csv.pcknow ------> \n",
      " Now convert it into .csv\n"
     ]
    }
   ],
   "source": [
    "run_featureExtractor_from_paths_in_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting from CSV with pixels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_featureExtractor_from_csv_with_images_pixels_as_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "****\n",
    "****\n",
    "****\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle file (file with openCV features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_data = pickle.load(open(\"features_from_imagepaths_csv.pck\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_and_lables = []\n",
    "for key, value in pickle_data.items():\n",
    "    features_and_lables.append(np.append(value, key.split('_')[0], axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating columns for the csv\n",
    "column = []\n",
    "for i in range(0,2048):\n",
    "    column.append('feat_'+str(i+1))\n",
    "column.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe_for_openCV_features = pd.DataFrame(columns = column, data=features_and_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_2040</th>\n",
       "      <th>feat_2041</th>\n",
       "      <th>feat_2042</th>\n",
       "      <th>feat_2043</th>\n",
       "      <th>feat_2044</th>\n",
       "      <th>feat_2045</th>\n",
       "      <th>feat_2046</th>\n",
       "      <th>feat_2047</th>\n",
       "      <th>feat_2048</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.01360799</td>\n",
       "      <td>0.012686276</td>\n",
       "      <td>0.08979333</td>\n",
       "      <td>0.18310963</td>\n",
       "      <td>-0.059490398</td>\n",
       "      <td>-0.05856323</td>\n",
       "      <td>0.14917304</td>\n",
       "      <td>0.14765403</td>\n",
       "      <td>0.048695706</td>\n",
       "      <td>-0.10776488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18533805</td>\n",
       "      <td>0.012999573</td>\n",
       "      <td>-0.0986951</td>\n",
       "      <td>0.112543255</td>\n",
       "      <td>0.17864294</td>\n",
       "      <td>0.007801774</td>\n",
       "      <td>-0.04314236</td>\n",
       "      <td>0.06073712</td>\n",
       "      <td>0.10852275</td>\n",
       "      <td>insect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.12430215</td>\n",
       "      <td>-0.0075551295</td>\n",
       "      <td>0.14839983</td>\n",
       "      <td>0.015258294</td>\n",
       "      <td>0.06451725</td>\n",
       "      <td>-0.008546388</td>\n",
       "      <td>0.13460904</td>\n",
       "      <td>0.011955053</td>\n",
       "      <td>-0.051461782</td>\n",
       "      <td>-0.0029106424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03564827</td>\n",
       "      <td>-0.040600453</td>\n",
       "      <td>0.0181083</td>\n",
       "      <td>0.0513236</td>\n",
       "      <td>0.037484955</td>\n",
       "      <td>-0.1103688</td>\n",
       "      <td>0.021537693</td>\n",
       "      <td>0.11762852</td>\n",
       "      <td>0.045252196</td>\n",
       "      <td>butterfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0024279747</td>\n",
       "      <td>-0.011422375</td>\n",
       "      <td>0.019622715</td>\n",
       "      <td>0.032322697</td>\n",
       "      <td>-0.017721262</td>\n",
       "      <td>-0.010654588</td>\n",
       "      <td>0.038415786</td>\n",
       "      <td>0.042495195</td>\n",
       "      <td>-0.001973614</td>\n",
       "      <td>0.0064269104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13815497</td>\n",
       "      <td>-0.0044013904</td>\n",
       "      <td>-0.05269962</td>\n",
       "      <td>0.13941616</td>\n",
       "      <td>0.13793239</td>\n",
       "      <td>-0.036049575</td>\n",
       "      <td>0.019900396</td>\n",
       "      <td>0.047929484</td>\n",
       "      <td>0.03682033</td>\n",
       "      <td>butterfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.00074665213</td>\n",
       "      <td>-0.045294546</td>\n",
       "      <td>0.012390873</td>\n",
       "      <td>0.08399318</td>\n",
       "      <td>0.0107911015</td>\n",
       "      <td>-0.08767704</td>\n",
       "      <td>0.07473835</td>\n",
       "      <td>0.11837611</td>\n",
       "      <td>-0.032467537</td>\n",
       "      <td>-0.12758476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100029394</td>\n",
       "      <td>-0.092320055</td>\n",
       "      <td>0.027188428</td>\n",
       "      <td>0.13856795</td>\n",
       "      <td>0.090444595</td>\n",
       "      <td>-0.044537976</td>\n",
       "      <td>0.021177402</td>\n",
       "      <td>0.07438172</td>\n",
       "      <td>0.05527107</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.021557711</td>\n",
       "      <td>-0.00021338205</td>\n",
       "      <td>0.023613863</td>\n",
       "      <td>0.017408762</td>\n",
       "      <td>-0.07281118</td>\n",
       "      <td>-0.01835224</td>\n",
       "      <td>0.07281118</td>\n",
       "      <td>0.03089315</td>\n",
       "      <td>-0.01958593</td>\n",
       "      <td>-0.029445702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18385535</td>\n",
       "      <td>0.022855816</td>\n",
       "      <td>0.0021406466</td>\n",
       "      <td>0.13598335</td>\n",
       "      <td>0.11853185</td>\n",
       "      <td>-0.024105359</td>\n",
       "      <td>0.031832285</td>\n",
       "      <td>0.07637017</td>\n",
       "      <td>0.0672026</td>\n",
       "      <td>bee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           feat_1          feat_2       feat_3       feat_4        feat_5  \\\n",
       "0     -0.01360799     0.012686276   0.08979333   0.18310963  -0.059490398   \n",
       "1     -0.12430215   -0.0075551295   0.14839983  0.015258294    0.06451725   \n",
       "2    0.0024279747    -0.011422375  0.019622715  0.032322697  -0.017721262   \n",
       "3  -0.00074665213    -0.045294546  0.012390873   0.08399318  0.0107911015   \n",
       "4    -0.021557711  -0.00021338205  0.023613863  0.017408762   -0.07281118   \n",
       "\n",
       "         feat_6       feat_7       feat_8        feat_9        feat_10  ...  \\\n",
       "0   -0.05856323   0.14917304   0.14765403   0.048695706    -0.10776488  ...   \n",
       "1  -0.008546388   0.13460904  0.011955053  -0.051461782  -0.0029106424  ...   \n",
       "2  -0.010654588  0.038415786  0.042495195  -0.001973614   0.0064269104  ...   \n",
       "3   -0.08767704   0.07473835   0.11837611  -0.032467537    -0.12758476  ...   \n",
       "4   -0.01835224   0.07281118   0.03089315   -0.01958593   -0.029445702  ...   \n",
       "\n",
       "     feat_2040      feat_2041     feat_2042    feat_2043    feat_2044  \\\n",
       "0   0.18533805    0.012999573    -0.0986951  0.112543255   0.17864294   \n",
       "1   0.03564827   -0.040600453     0.0181083    0.0513236  0.037484955   \n",
       "2   0.13815497  -0.0044013904   -0.05269962   0.13941616   0.13793239   \n",
       "3  0.100029394   -0.092320055   0.027188428   0.13856795  0.090444595   \n",
       "4   0.18385535    0.022855816  0.0021406466   0.13598335   0.11853185   \n",
       "\n",
       "      feat_2045    feat_2046    feat_2047    feat_2048      label  \n",
       "0   0.007801774  -0.04314236   0.06073712   0.10852275     insect  \n",
       "1    -0.1103688  0.021537693   0.11762852  0.045252196  butterfly  \n",
       "2  -0.036049575  0.019900396  0.047929484   0.03682033  butterfly  \n",
       "3  -0.044537976  0.021177402   0.07438172   0.05527107      other  \n",
       "4  -0.024105359  0.031832285   0.07637017    0.0672026        bee  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe_for_openCV_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save as CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe_for_openCV_features.to_csv('test_opencv.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "butterfly    2500\n",
       "wasp         2500\n",
       "bee          2500\n",
       "insect       2500\n",
       "other        2500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDFOpencV = pd.read_csv('../DATA/TEST/test_opencv.csv')\n",
    "testDFOpencV.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wasp         600\n",
       "insect       600\n",
       "bee          600\n",
       "other        600\n",
       "butterfly    600\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validDFOpencV = pd.read_csv('../DATA/VALID/valid_opencv.csv')\n",
    "validDFOpencV.label.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
