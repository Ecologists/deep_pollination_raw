{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>YMD</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Flower</th>\n",
       "      <th>collection</th>\n",
       "      <th>user_id</th>\n",
       "      <th>B&amp;W_taxonomy</th>\n",
       "      <th>Nom_taxon</th>\n",
       "      <th>ORDRE</th>\n",
       "      <th>IFOR</th>\n",
       "      <th>SPFM</th>\n",
       "      <th>FM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://spgp-api.65mo.fr/api/containers/spgp/d...</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>45.363808</td>\n",
       "      <td>6.514947</td>\n",
       "      <td>Les Trèfles ? fleurs blanches ou roses en boul...</td>\n",
       "      <td>1</td>\n",
       "      <td>12657</td>\n",
       "      <td>Bees</td>\n",
       "      <td>L'Abeille mellifère (Apis mellifera)</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apoidea</td>\n",
       "      <td>Apidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://spgp-api.65mo.fr/api/containers/spgp/d...</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>45.363808</td>\n",
       "      <td>6.514947</td>\n",
       "      <td>Les Trèfles ? fleurs blanches ou roses en boul...</td>\n",
       "      <td>1</td>\n",
       "      <td>12657</td>\n",
       "      <td>Bees</td>\n",
       "      <td>Les Bourdons noirs à bande(s) jaune(s) et cul ...</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apoidea</td>\n",
       "      <td>Apidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://spgp-api.65mo.fr/api/containers/spgp/d...</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>48.844975</td>\n",
       "      <td>2.358313</td>\n",
       "      <td>Acanthus mollis</td>\n",
       "      <td>2</td>\n",
       "      <td>10918</td>\n",
       "      <td>Bees</td>\n",
       "      <td>Les Bourdons noirs à bande(s) jaune(s) et cul ...</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apoidea</td>\n",
       "      <td>Apidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://spgp-api.65mo.fr/api/containers/spgp/d...</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>48.844975</td>\n",
       "      <td>2.358313</td>\n",
       "      <td>Acanthus mollis</td>\n",
       "      <td>2</td>\n",
       "      <td>10918</td>\n",
       "      <td>Bees</td>\n",
       "      <td>L'Abeille mellifère (Apis mellifera)</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apoidea</td>\n",
       "      <td>Apidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://spgp-api.65mo.fr/api/containers/spgp/d...</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>44.711017</td>\n",
       "      <td>4.568069</td>\n",
       "      <td>Les Orchidées ? fleurs blanches, jaunes ou ver...</td>\n",
       "      <td>3</td>\n",
       "      <td>11784</td>\n",
       "      <td>Other insects</td>\n",
       "      <td>Les Sauterelles (Tettigoniidae)</td>\n",
       "      <td>Orthoptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tettigonioidea</td>\n",
       "      <td>Tettigoniidae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL         YMD        Lat  \\\n",
       "0  https://spgp-api.65mo.fr/api/containers/spgp/d...  2019-06-12  45.363808   \n",
       "1  https://spgp-api.65mo.fr/api/containers/spgp/d...  2019-06-12  45.363808   \n",
       "2  https://spgp-api.65mo.fr/api/containers/spgp/d...  2019-06-20  48.844975   \n",
       "3  https://spgp-api.65mo.fr/api/containers/spgp/d...  2019-06-20  48.844975   \n",
       "4  https://spgp-api.65mo.fr/api/containers/spgp/d...  2019-06-12  44.711017   \n",
       "\n",
       "       Long                                             Flower  collection  \\\n",
       "0  6.514947  Les Trèfles ? fleurs blanches ou roses en boul...           1   \n",
       "1  6.514947  Les Trèfles ? fleurs blanches ou roses en boul...           1   \n",
       "2  2.358313                                    Acanthus mollis           2   \n",
       "3  2.358313                                    Acanthus mollis           2   \n",
       "4  4.568069  Les Orchidées ? fleurs blanches, jaunes ou ver...           3   \n",
       "\n",
       "   user_id   B&W_taxonomy                                          Nom_taxon  \\\n",
       "0    12657           Bees               L'Abeille mellifère (Apis mellifera)   \n",
       "1    12657           Bees  Les Bourdons noirs à bande(s) jaune(s) et cul ...   \n",
       "2    10918           Bees  Les Bourdons noirs à bande(s) jaune(s) et cul ...   \n",
       "3    10918           Bees               L'Abeille mellifère (Apis mellifera)   \n",
       "4    11784  Other insects                    Les Sauterelles (Tettigoniidae)   \n",
       "\n",
       "         ORDRE IFOR            SPFM             FM  \n",
       "0  Hymenoptera  NaN         Apoidea         Apidae  \n",
       "1  Hymenoptera  NaN         Apoidea         Apidae  \n",
       "2  Hymenoptera  NaN         Apoidea         Apidae  \n",
       "3  Hymenoptera  NaN         Apoidea         Apidae  \n",
       "4   Orthoptera  NaN  Tettigonioidea  Tettigoniidae  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spipoll_export_202012301551.txt', delimiter=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['B&W_taxonomy'] = data['B&W_taxonomy'].replace(\"Bees\",\"bee\")\n",
    "data['B&W_taxonomy'] = data['B&W_taxonomy'].replace(\"Wasps\",\"wasp\")\n",
    "data['B&W_taxonomy'] = data['B&W_taxonomy'].replace(\"Other insects\",\"insect\")\n",
    "data['B&W_taxonomy'] = data['B&W_taxonomy'].replace(\"butterflies\",\"butterfly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bee = data[data[\"B&W_taxonomy\"]=='bee']\n",
    "data_wasp = data[data[\"B&W_taxonomy\"]=='wasp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the test\n",
    "\n",
    "(be carefull with the number of images to test it can be quite expensive in terms of memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_images = 500\n",
    "resolution_to_test = [64, 128, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the images & preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "images = []\n",
    "label = []\n",
    "#Label : 0 for bees & 1 for wasps\n",
    "\n",
    "for i in range(number_images):\n",
    "    images.append(io.imread(data_bee[\"URL\"].iloc[i]))\n",
    "    images.append(io.imread(data_wasp[\"URL\"].iloc[i]))\n",
    "    label.append(0)\n",
    "    label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(images)):\n",
    "    shape = np.shape(images[i])\n",
    "    if(len(shape)==2 or shape[2] != 3):\n",
    "        images.pop(i)\n",
    "        label.pop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No strange images among the first 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_resize(img):\n",
    "    x = np.shape(img)\n",
    "    \n",
    "    diff = np.abs(x[0] - x[1])\n",
    "    a = int(diff/2)\n",
    "    \n",
    "    if(len(x) == 3):\n",
    "        if (x[0] < x[1]):\n",
    "            b = int(x[1]-(diff/2))\n",
    "            res = img[:,a:b,:]\n",
    "        else:\n",
    "            b = int(x[0]-(diff/2))\n",
    "            res = img[a:b,:,:]\n",
    "    else:\n",
    "        if (x[0] < x[1]):\n",
    "            b = int(x[1]-(diff/2))\n",
    "            res = img[:,a:b]\n",
    "        else:\n",
    "            b = int(x[0]-(diff/2))\n",
    "            res = img[a:b,:]\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thibaut\\anaconda3\\envs\\tensor\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "images_resized=[]\n",
    "for i in range(0,np.shape(images)[0]):\n",
    "    images_resized.append(perfect_resize(images[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the line below to remove the raw images as we don't need them anymore \n",
    "\n",
    "(but you will have to redownload them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if all images are squared images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(images_resized)):\n",
    "    if(np.shape(images_resized[i])[0] != np.shape(images_resized[i])[1]):\n",
    "        print(np.shape(images_resized[0])[0],np.shape(images_resized)[1])\n",
    "        print(\"Erreur, des images ont mal été modifiés :\" , i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image reduction to the one that need to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "images_all_resolutions = []\n",
    "for i in range(len(resolution_to_test)):\n",
    "    images_all_resolutions.append([])\n",
    "    \n",
    "for i in range(0,len(images_resized)):\n",
    "    temp = Image.fromarray(images_resized[i])\n",
    "    for j in range(len(resolution_to_test)):\n",
    "        resolution = resolution_to_test[j]\n",
    "        images_all_resolutions[j].append(np.array(temp.resize(size=(resolution, resolution))))\n",
    "    if (i%100==0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will flatten the array to insert it into the dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(images_resized)):\n",
    "    for j in range(len(resolution_to_test)):\n",
    "        images_all_resolutions[j][i] = images_all_resolutions[j][i].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert the array img into a dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_all_resolutions = []\n",
    "for i in range(len(resolution_to_test)):\n",
    "    column_all_resolutions.append([])\n",
    "\n",
    "for index_resolution, resolution in enumerate(resolution_to_test):\n",
    "    for i in range(0,resolution*resolution):\n",
    "        name = 'pixel_'+str(1+int(i/resolution))+'_'+str(1+(i%resolution))\n",
    "        column_all_resolutions[index_resolution].append(name+'_R')\n",
    "        column_all_resolutions[index_resolution].append(name+'_G')\n",
    "        column_all_resolutions[index_resolution].append(name+'_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "labels_dataframe = pd.DataFrame(columns=['label'], data=label)\n",
    "\n",
    "for index_resolution, resolution in enumerate(resolution_to_test):\n",
    "    to_be_merged_dataframe = pd.DataFrame(columns = column_all_resolutions[index_resolution], data=images_all_resolutions[index_resolution])    \n",
    "    dataframes[resolution] = to_be_merged_dataframe.merge(labels_dataframe, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model depending on the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 36s 3s/step - loss: 0.7508 - accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5459 - accuracy: 0.6154\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2987 - accuracy: 0.9231\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1217 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.9356 - accuracy: 0.3846\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2210 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0445 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 37s 3s/step - loss: 0.6758 - accuracy: 0.6154\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0899 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0038 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for  resolution in resolution_to_test:\n",
    "    y = dataframes[resolution][\"label\"]\n",
    "    X = dataframes[resolution].drop([\"label\"], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    y_test = to_categorical(y_test, num_classes=2)\n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    X_train = X_train.reshape(len(X_train),resolution,resolution,3)\n",
    "    X_test = X_test.reshape(len(X_test),resolution,resolution,3)\n",
    "    X_train = X_train / 255.\n",
    "    X_test = X_test / 255.\n",
    "    \n",
    "    base_model = ResNet152V2(include_top=False, weights='imagenet')\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, #validation_split=0.2,\n",
    "              epochs=5,\n",
    "              verbose=1)\n",
    "    \n",
    "    scores.append(model.evaluate(X_test, y_test,verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_reso = [scores[i][1] for i in range(len(scores))]\n",
    "\n",
    "x = np.arange(len(resolution_to_test))  \n",
    "width = 0.5  \n",
    "\n",
    "fig, ax = plt.subplots(figsize =(20,5))\n",
    "rects1 = ax.bar(x, scores_reso, width=width, label='Test')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Scores by type of classifier')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(resolution_to_test)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
